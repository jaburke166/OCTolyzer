{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24243f20-086c-4b6f-abfb-d3b00421a226",
   "metadata": {},
   "source": [
    "# Debugging Jupyter Notebook for OCTolyzer's collating of files \n",
    "This notebook copies the step-by-step process of OCTolyzer's final step when batch-processing to collate the results of all files processed, and should provide the end-user with the means of debugging the pipeline by testing each step individually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff6a7e7-2b24-4504-b50a-009a5d493119",
   "metadata": {},
   "source": [
    "### Add OCTolyzer to system paths to permit access to analysis files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8bab7bc-092d-4dac-b72f-adcfb4e1d305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from importlib import reload\n",
    "sys.path.append(r'../')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb8c4e1-be1d-483a-8dab-d0500477b4ab",
   "metadata": {},
   "source": [
    "### Import necessary packages and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a553906a-7170-4089-bd5a-d8742377eb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path, PosixPath, WindowsPath\n",
    "from PIL import ImageOps, Image\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import segmentation, morphology\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd4a13d8-0bd7-4cbb-9133-2cc95c6aff6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s1522100/Documents/OCTolyzer/debugging/../octolyzer/segment/octseg/choroidalyzer_inference.py:9: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from octolyzer.measure.slo import slo_measurement\n",
    "from octolyzer import analyse, collate_data, utils\n",
    "from octolyzer.segment.octseg import choroidalyzer_inference, deepgpet_inference\n",
    "from octolyzer.segment.sloseg import slo_inference, avo_inference, fov_inference\n",
    "from octolyzer.measure.bscan.thickness_maps import grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399426dc-84cf-4f2a-9541-10489393f955",
   "metadata": {},
   "source": [
    "### Load in measurements for a specific `.vol` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2fb0826-9927-4d07-8a4f-d5b1f1bd8bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_path = '../demo/output_020225/Radial_1'\n",
    "logging_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "602a81a7-0036-4906-91f3-847d0d900986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in measurements...\n",
      "Successfully loaded in all measurements!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "msg = \"Loading in measurements...\"\n",
    "print(msg)\n",
    "logging_list.append(msg)\n",
    "fname = os.path.split(fname_path)[-1]\n",
    "output_fname = os.path.join(fname_path, f\"{fname}_output.xlsx\")\n",
    "\n",
    "# Load metadata\n",
    "meta_df = pd.read_excel(output_fname, sheet_name=\"metadata\")\n",
    "oct_dfs = []\n",
    "slo_dfs = []\n",
    "\n",
    "# Load in SLO measurements\n",
    "if meta_df.bscan_type.iloc[0] == \"Peripapillary\":\n",
    "    for r in [\"B\", \"C\", \"whole\"]:\n",
    "        try:\n",
    "            df = pd.read_excel(output_fname, sheet_name=f\"slo_measurements_{r}\")\n",
    "        except:\n",
    "            df = pd.DataFrame()\n",
    "        slo_dfs.append(df)\n",
    "else:\n",
    "    try:\n",
    "        df = pd.read_excel(output_fname, sheet_name=f\"slo_measurements_whole\")\n",
    "    except:\n",
    "        df = pd.DataFrame()\n",
    "    slo_dfs.append(df)\n",
    "\n",
    "# Load in OCT measurements\n",
    "if meta_df.bscan_type.iloc[0] == \"Ppole\":\n",
    "    keys = ['etdrs_measurements', 'etdrs_volume_measurements', 'square_measurements', 'square_volume_measurements']\n",
    "else:\n",
    "    keys = ['oct_measurements']\n",
    "for key in keys:\n",
    "    try:\n",
    "        df = pd.read_excel(output_fname, sheet_name=key)\n",
    "        oct_dfs.append(df)\n",
    "    except:\n",
    "        print(f'{key} does not exist. Skipping.')\n",
    "\n",
    "msg = \"Successfully loaded in all measurements!\\n\"\n",
    "print(msg)\n",
    "logging_list.append(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298c4721-8d7e-43a9-b205-720947300b1b",
   "metadata": {},
   "source": [
    "### Collate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6c6267b-45bc-44b8-a62d-55193aba9e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {\n",
    "    \"save_individual_segmentations\": 1,\n",
    "    \"save_individual_images\": 1,\n",
    "    \"preprocess_bscans\": 1,\n",
    "    \"analyse_choroid\": 1,\n",
    "    \"analyse_slo\": 1,\n",
    "    \"custom_maps\": [], # this cannot be \"0\" like it is in config.txt - it is an empty list\n",
    "    \"analyse_all_maps\": 1,\n",
    "    \"analyse_square_grid\": 1,\n",
    "    \"choroid_measure_type\": \"perpendicular\",\n",
    "    \"linescan_roi_distance\": 3000\n",
    "}\n",
    "\n",
    "# flags for choroid analysis, preprocessing bscans\n",
    "preprocess_data = param_dict[\"preprocess_bscans\"]\n",
    "\n",
    "# For saving out representative Bscan/SLO/segmentation masks\n",
    "save_ind_segmentations = param_dict[\"save_individual_segmentations\"]\n",
    "save_ind_images = param_dict[\"save_individual_images\"]\n",
    "\n",
    "# Custom retinal thickness maps\n",
    "custom_maps = param_dict[\"custom_maps\"]\n",
    "all_maps = param_dict[\"analyse_all_maps\"]\n",
    "\n",
    "# analysing choroid?\n",
    "analyse_choroid = param_dict['analyse_choroid']\n",
    "\n",
    "# square grid for Ppole\n",
    "sq_grid_flag = param_dict['analyse_square_grid']\n",
    "\n",
    "# analysing SLO?\n",
    "analyse_slo_flag = param_dict['analyse_slo']\n",
    "\n",
    "# User-specified measure type for choroid\n",
    "chor_measure_type = param_dict['choroid_measure_type']\n",
    "\n",
    "# User-specified ROI distance either side of fovea\n",
    "macula_rum = param_dict['linescan_roi_distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6372681-55cb-4c3e-a995-dec92344d768",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = '../demo/output_020225'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4014fbf2-131b-42d4-8300-4271d5dd9912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('../demo/input/Linescan_1.vol'),\n",
       " PosixPath('../demo/input/Peripapillary_1.vol'),\n",
       " PosixPath('../demo/input/Ppole_1.vol'),\n",
       " PosixPath('../demo/input/Radial_1.vol')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol_paths = sorted(Path('../demo/input').glob(\"*.vol\"))\n",
    "vol_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ace7043-163f-4102-827f-993568aa91c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analysing...:  25%|█████████▊                             | 1/4 [00:00<00:00,  7.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previously analysed Linescan_1.\n",
      "Loading in measurements...\n",
      "Successfully loaded in all measurements!\n",
      "\n",
      "Previously analysed Peripapillary_1.\n",
      "Loading in measurements...\n",
      "Successfully loaded in all measurements!\n",
      "\n",
      "Previously analysed Ppole_1.\n",
      "Loading in measurements...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "square_measurements does not exist. Skipping.\n",
      "square_volume_measurements does not exist. Skipping.\n",
      "Successfully loaded in all measurements!\n",
      "\n",
      "Previously analysed Radial_1.\n",
      "Loading in measurements...\n",
      "Successfully loaded in all measurements!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "oct_slo_result_dict = {}\n",
    "for path in tqdm(vol_paths, desc='Analysing...', leave=False):\n",
    "    \n",
    "    # OS compatibility\n",
    "    if isinstance(path, PosixPath):\n",
    "        fname_type = str(path).split('/')[-1]\n",
    "    elif isinstance(path, WindowsPath):\n",
    "        fname_type = str(path).split(\"\\\\\")[-1]\n",
    "    oct_slo_result_dict[fname_type] = {}\n",
    "    fname = fname_type.split(\".\")[0]\n",
    "    \n",
    "    fname_path = os.path.join(save_directory, fname)\n",
    "    output_fname = os.path.join(fname_path, f\"{fname}_output.xlsx\")\n",
    "    slo_mannotations = ( len(list(Path(fname_path).glob(\"*.nii.gz\"))) - len(list(Path(fname_path).glob(\"*_used.nii.gz\"))) )  > 0\n",
    "    param_dict['manual_annotation'] = int(slo_mannotations)\n",
    "    if os.path.exists(output_fname) and not slo_mannotations:\n",
    "        print(f\"Previously analysed {fname}.\")\n",
    "        ind_df, slo_dfs, oct_dfs, log = collate_data._load_files(fname_path, logging_list=[])\n",
    "        oct_slo_result_dict[fname_type]['metadata'] = ind_df\n",
    "        if analyse_slo_flag:\n",
    "            oct_slo_result_dict[fname_type]['slo'] = slo_dfs\n",
    "        else:\n",
    "            oct_slo_result_dict[fname_type]['slo'] = [pd.DataFrame()]\n",
    "        oct_slo_result_dict[fname_type]['oct'] = oct_dfs\n",
    "        oct_slo_result_dict[fname_type]['log'] = log\n",
    "            \n",
    "    elif \"_ANGIO\" in fname:\n",
    "        print(f\"{fname} is an OCT-A scan. Skipping.\\n\\n\")\n",
    "        \n",
    "    else:\n",
    "        if robust_run:\n",
    "            try:\n",
    "                output = analyse.analyse(path, \n",
    "                                save_directory, \n",
    "                                choroidalyzer, \n",
    "                                slosegmenter, \n",
    "                                avosegmenter,\n",
    "                                fovsegmenter,\n",
    "                                deepgpet,\n",
    "                                param_dict)\n",
    "                slo_analysis_output, oct_analysis_output = output\n",
    "                oct_slo_result_dict[fname_type]['metadata'] = oct_analysis_output[0]\n",
    "                if slo_analysis_output is not None and analyse_slo_flag:\n",
    "                    oct_slo_result_dict[fname_type]['slo'] = slo_analysis_output[1]\n",
    "                else:\n",
    "                    oct_slo_result_dict[fname_type]['slo'] = [pd.DataFrame()]\n",
    "                oct_slo_result_dict[fname_type]['oct'] = oct_analysis_output[3]\n",
    "                oct_slo_result_dict[fname_type]['log'] = oct_analysis_output[-1]\n",
    "            except Exception as e:\n",
    "                # print and log error\n",
    "                user_fail = f\"\\nFailed to analyse {fname}.\"\n",
    "                log = utils.print_error(e)\n",
    "                logging_list = [user_fail] + log\n",
    "                skip = \"Skipping and moving to next file.\\nCheck data input and/or set robust_run to 0 to debug code.\\n\"\n",
    "                print(skip)\n",
    "\n",
    "                # Try at least save out metadata from loading volfile for failed\n",
    "                # file - making sure to mark in FAILED column\n",
    "                try:\n",
    "                    _, metadata, _, _, _ = utils.load_volfile(path, verbose=False)\n",
    "                    metadata['FAILED'] = True\n",
    "                    if metadata[\"bscan_type\"] == 'Peripapillary':\n",
    "                        del metadata['stxy_coord']\n",
    "\n",
    "                # Catch any exceptions with failing to even load image and metadata from \n",
    "                # volfile\n",
    "                except:\n",
    "                    metadata = {'Filename':os.path.split(path)[1]}\n",
    "                    fail_load = \"Failed to even load path, check utils.load_volfile\"\n",
    "                    print(fail_load)\n",
    "                    log.append(fail_load)\n",
    "\n",
    "                oct_slo_result_dict[fname_type]['metadata'] = metadata\n",
    "                oct_slo_result_dict[fname_type]['oct'] = logging_list[0]\n",
    "                oct_slo_result_dict[fname_type]['log'] = logging_list\n",
    "                \n",
    "        else:\n",
    "            output = analyse.analyse(path, \n",
    "                            save_directory, \n",
    "                            choroidalyzer, \n",
    "                            slosegmenter, \n",
    "                            avosegmenter,\n",
    "                            fovsegmenter,\n",
    "                            deepgpet,\n",
    "                            param_dict)\n",
    "            slo_analysis_output, oct_analysis_output = output\n",
    "            oct_slo_result_dict[fname_type]['metadata'] = oct_analysis_output[0]\n",
    "            if slo_analysis_output is not None and analyse_slo_flag:\n",
    "                oct_slo_result_dict[fname_type]['slo'] = slo_analysis_output[1]\n",
    "            else:\n",
    "                oct_slo_result_dict[fname_type]['slo'] = [pd.DataFrame()]\n",
    "            oct_slo_result_dict[fname_type]['oct'] = oct_analysis_output[3]\n",
    "            oct_slo_result_dict[fname_type]['log'] = oct_analysis_output[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93dc6dfa-99cd-433e-afca-be965d884773",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = oct_slo_result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8fce040-6e7a-43bd-8aea-f8b82c9fc4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_slo = param_dict['analyse_slo']\n",
    "MODULE_PATH = '../'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36a0d22-7126-4fa8-8728-27633f641131",
   "metadata": {},
   "source": [
    "### Loop over loaded in results for every file and collate together into unified DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "526aa15c-0855-4e85-a36a-3f7f5d2454ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting all results together into one output file.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Collecting all results together into one output file.\")\n",
    "all_logging_list = []\n",
    "all_slo_df = pd.DataFrame()\n",
    "all_ind_df = pd.DataFrame()\n",
    "all_oct_linescan_df = pd.DataFrame()\n",
    "all_oct_ppole_df = pd.DataFrame()\n",
    "all_oct_sq_ppole_df = pd.DataFrame()\n",
    "all_oct_peri_df = pd.DataFrame()\n",
    "all_oct_radial_df = pd.DataFrame()\n",
    "for fname_type, output in result_dict.items():\n",
    "    \n",
    "    fname = fname_type.split(\".\")[0]\n",
    "    all_logging_list.append(f\"\\n\\nANALYSIS LOG OF {fname_type}\")\n",
    "\n",
    "    # Create default dataframe for failed individuals and save out error\n",
    "    if isinstance(output['oct'], str):\n",
    "        log = output['log']\n",
    "        metadata = output['metadata']\n",
    "        slo_dfs = pd.DataFrame()\n",
    "        oct_dfs = pd.DataFrame()\n",
    "        fname_path = os.path.join(save_directory, fname)\n",
    "        all_logging_list.extend(log)    \n",
    "        with open(os.path.join(fname_path, f\"{fname}_log.txt\"), \"w\") as f:\n",
    "            for line in log:\n",
    "                f.write(line+\"\\n\")\n",
    "        ind_df = pd.DataFrame(metadata, index=[0])\n",
    "    \n",
    "    # Otherwise, collate measurements and save out segmentations if specified\n",
    "    else:    \n",
    "        \n",
    "        ind_df = output['metadata']\n",
    "        bscan_type = ind_df.bscan_type.iloc[0]\n",
    "        slo_dfs = output['slo']\n",
    "        oct_dfs = output['oct']\n",
    "        N_oct = len(oct_dfs)\n",
    "        logging_list = output['log']\n",
    "\n",
    "        # If cannot find measurements/etadata, create default dataframe and bypass\n",
    "        # the segmentation visualisation\n",
    "        all_logging_list.extend(logging_list)\n",
    "\n",
    "        # process SLO measurement DFs and save out global dataframe\n",
    "        flat_slo_df = pd.DataFrame()\n",
    "        if len(slo_dfs[0]) > 0:\n",
    "            rtypes = []\n",
    "            for df in slo_dfs:\n",
    "                if len(df) == 0:\n",
    "                    continue\n",
    "                # flatten\n",
    "                dfarr = df.values.flatten()\n",
    "\n",
    "                # Collect all columns in flattened DF\n",
    "                dfcols = list(df.columns)\n",
    "                rtype = df.zone.iloc[0]\n",
    "                rtypes.append(rtype)\n",
    "                vtypes = df.vessel_map.values\n",
    "                dfcols = [col+f\"_{vtype}_{rtype}\" for vtype in vtypes for col in dfcols]\n",
    "                df_flatten = pd.DataFrame(dfarr.reshape(1,-1), columns = dfcols, index=[0])\n",
    "\n",
    "                # Remove indexing columns and concatenate with different zones\n",
    "                cols_to_drop = df_flatten.columns[df_flatten.columns.str.contains(\"vessel_map|zone\")]\n",
    "                df_flatten = df_flatten.drop(cols_to_drop, axis=1, inplace=False)\n",
    "                flat_slo_df = pd.concat([flat_slo_df, df_flatten], axis=1)    \n",
    "\n",
    "            # Order feature columns by importance in literature\n",
    "            order_str = [\"fractal_dimension\", \"vessel_density\", \"tortuosity_density\", 'average_global_calibre', \n",
    "                         'average_local_calibre', 'CRAE_Knudtson', 'CRVE_Knudtson', 'AVR']\n",
    "            order_str_rv = [col+f\"_{vtype}_{rtype}\" \n",
    "                                for rtype in rtypes[::-1] \n",
    "                                    for vtype in vtypes for col in order_str]\n",
    "            flat_slo_df = flat_slo_df[order_str_rv]\n",
    "            flat_slo_df = flat_slo_df.loc[:, ~(flat_slo_df == -1).any()]\n",
    "            flat_slo_df = flat_slo_df.rename({f\"AVR_artery-vein_{rtype}\":f\"AVR_{rtype}\" \n",
    "                                              for rtype in rtypes}, inplace=False, axis=1)\n",
    "\n",
    "            # Concatenate measurements with metadata filename\n",
    "            ind_slo_df = pd.concat([ind_df['Filename'], flat_slo_df], axis=1)\n",
    "\n",
    "        # process OCT measurement DFs and save out global dataframe\n",
    "        flat_oct_df = pd.DataFrame()\n",
    "        flat_sq_oct_df = pd.DataFrame()\n",
    "\n",
    "        # For Peripapillary, H-line/V-line and Radial scans\n",
    "        if bscan_type != 'Ppole':\n",
    "            for idx, df in enumerate(oct_dfs):\n",
    "                \n",
    "                # Remove choroid measurements if not analysing choroid\n",
    "                if not analyse_choroid:\n",
    "                    df = df[df['layer'] != 'CHORupper_CHORlower']\n",
    "\n",
    "                # Collect all layers in flattened DF\n",
    "                ltypes = df.layer.values\n",
    "                \n",
    "                # Flatten and collect all flattened columns through combining\n",
    "                # layers, features and potentially scan number\n",
    "                if bscan_type == \"Peripapillary\":\n",
    "                    dfarr = df.values[:,1:].flatten()\n",
    "                    dfcols = list(df.columns[1:])\n",
    "                    dfcols = [f\"{layer}_{col}\" for layer in ltypes for col in dfcols]\n",
    "                \n",
    "                else:\n",
    "                    dfarr = df.values[:,2:].flatten()\n",
    "                    ltypes = df.layer.drop_duplicates().values\n",
    "                    dfcols = list(df.columns[2:])\n",
    "                    scan_idxs = df.scan_number.drop_duplicates().values\n",
    "                    dfcols = [f\"{layer}_{col}_{idx}\" for layer in ltypes for idx in scan_idxs for col in dfcols]\n",
    "                \n",
    "                df_flatten = pd.DataFrame(dfarr.reshape(1,-1), columns = dfcols, index=[0])\n",
    "\n",
    "                # Concatenate to flatten dF\n",
    "                flat_oct_df = pd.concat([flat_oct_df, df_flatten], axis=1).dropna(axis=1)\n",
    "    \n",
    "        else:\n",
    "            \n",
    "            # Loop across measurement DataFrames for Ppole features\n",
    "            for idx, df in enumerate(oct_dfs[:2]):\n",
    "\n",
    "                # Remove choroid measurements if not analysing choroid\n",
    "                if not analyse_choroid:\n",
    "                    df = df[~df['map_name'].isin(['choroid_vessel', 'choroid_CVI', 'choroid'])]\n",
    "                \n",
    "                # flatten\n",
    "                dfarr = df.values[:,2:].flatten()\n",
    "            \n",
    "                # Collect all columns in flattened DF. \n",
    "                dfcols = list(df.columns[2:])\n",
    "                mtypes = df.map_name.values\n",
    "                retinal_maps = [mtype for mtype in mtypes if \"choroid\" not in mtype]\n",
    "                for key in ['retina', 'inner_retina', 'outer_retina']:\n",
    "                    if key in retinal_maps:\n",
    "                        retinal_maps.remove(key)\n",
    "               \n",
    "                # For thickness/area, then for volume\n",
    "                if idx == 0:\n",
    "                    dfcols = [col+f\"_{mtype}_[um]\" \n",
    "                                      if mtype not in ['choroid_CVI', 'choroid_vessel'] \n",
    "                                      else [col+f\"_{mtype}\", col+f\"_{mtype}_[um2]\"][mtype=='vessel'] \n",
    "                                for mtype in mtypes for col in dfcols]\n",
    "                else:\n",
    "                    dfcols = [col+f\"_{mtype}_[mm3]\" for mtype in mtypes for col in dfcols]\n",
    "\n",
    "                df_flatten = pd.DataFrame(dfarr.reshape(1,-1), columns = dfcols, index=[0])\n",
    "\n",
    "                # Concatenate to flatten dataframe\n",
    "                flat_oct_df = pd.concat([flat_oct_df, df_flatten], axis=1).dropna(axis=1)\n",
    "\n",
    "            # This is for Ppole scans where we have thickness and volume measurements\n",
    "            if N_oct > 2:\n",
    "                for idx, df in enumerate(oct_dfs[2:]):\n",
    "                    # flatten\n",
    "                    dfarr = df.values[:,2:].flatten()\n",
    "                \n",
    "                    # Collect all columns in flattened DF. \n",
    "                    dfcols = list(df.columns[2:])\n",
    "                    mtypes = df.map_name.values\n",
    "                    retinal_maps = [mtype for mtype in mtypes if \"choroid\" not in mtype]\n",
    "                    for key in ['retina', 'inner_retina', 'outer_retina']:\n",
    "                        if key in retinal_maps:\n",
    "                            retinal_maps.remove(key)\n",
    "                   \n",
    "                    # For thickness/area, then for volume\n",
    "                    if idx == 0:\n",
    "                        dfcols = [col+f\"_{mtype}_[um]\" \n",
    "                                          if mtype not in ['choroid_CVI', 'choroid_vessel'] \n",
    "                                          else [col+f\"_{mtype}\", col+f\"_{mtype}_[um2]\"][mtype=='vessel'] \n",
    "                                    for mtype in mtypes for col in dfcols]\n",
    "                    else:\n",
    "                        dfcols = [col+f\"_{mtype}_[mm3]\" for mtype in mtypes for col in dfcols]\n",
    "\n",
    "                    df_flatten = pd.DataFrame(dfarr.reshape(1,-1), columns = dfcols, index=[0])\n",
    "\n",
    "                    # Concatenate to flatten dataframe\n",
    "                    flat_sq_oct_df = pd.concat([flat_sq_oct_df, df_flatten], axis=1).dropna(axis=1)\n",
    "                    \n",
    "        # Concatenate measurements with metadata\n",
    "        ind_oct_df = pd.concat([ind_df['Filename'], flat_oct_df], axis=1)\n",
    "        if N_oct > 2:\n",
    "            ind_sq_oct_df = pd.concat([ind_df['Filename'], flat_sq_oct_df], axis=1)\n",
    "            \n",
    "        # Concatenate to create global dataframe of SLO results\n",
    "        if len(slo_dfs[0]) > 0:\n",
    "            all_slo_df = pd.concat([all_slo_df, ind_slo_df], axis=0)\n",
    "\n",
    "        # Append row to global dataframe of OCT results dependent on bscan type\n",
    "        if bscan_type == 'Ppole':\n",
    "            all_oct_ppole_df = pd.concat([all_oct_ppole_df, ind_oct_df], axis=0)\n",
    "            if N_oct > 2:\n",
    "                all_oct_sq_ppole_df = pd.concat([all_oct_sq_ppole_df, ind_sq_oct_df], axis=0)\n",
    "        elif bscan_type == 'Peripapillary':\n",
    "            all_oct_peri_df = pd.concat([all_oct_peri_df, ind_oct_df], axis=0)\n",
    "        elif bscan_type == 'Radial':\n",
    "            all_oct_radial_df = pd.concat([all_oct_radial_df, ind_oct_df], axis=0)\n",
    "        else:\n",
    "            all_oct_linescan_df = pd.concat([all_oct_linescan_df, ind_oct_df], axis=0)\n",
    "\n",
    "    # Concenate metadata to global dataframe of metadata, robust to suppress NaN warnings\n",
    "    # from different Bscan types having different columns\n",
    "    if (len(all_ind_df)) > 0 & (len(ind_df) > 0):\n",
    "        all_ind_df = pd.concat([all_ind_df.fillna(\"NA\"), ind_df.fillna(\"NA\")], axis=0)\n",
    "    else:\n",
    "        all_ind_df = ind_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b23852-cb12-4a9b-9007-65efe5a42a4f",
   "metadata": {},
   "source": [
    "### Save out collated results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "689cddf2-43b5-4a12-9806-35ecb685bf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index\n",
    "all_ind_df = all_ind_df.reset_index(drop=True)\n",
    "all_slo_df = all_slo_df.reset_index(drop=True)\n",
    "all_oct_ppole_df = all_oct_ppole_df.reset_index(drop=True)\n",
    "all_oct_sq_ppole_df = all_oct_sq_ppole_df.reset_index(drop=True)\n",
    "all_oct_peri_df = all_oct_peri_df.reset_index(drop=True)\n",
    "all_oct_linescan_df = all_oct_linescan_df.reset_index(drop=True)\n",
    "all_oct_radial_df = all_oct_radial_df.reset_index(drop=True)\n",
    "\n",
    "# Remove any rows in all_oct_linescan_df which are just -1s, i.e. fovea was not detected\n",
    "all_oct_linescan_df = all_oct_linescan_df[~(all_oct_linescan_df.iloc[:, 1:]==-1).all(axis=1)]\n",
    "all_oct_radial_df = all_oct_radial_df[~(all_oct_radial_df.iloc[:, 1:]==-1).all(axis=1)]\n",
    "\n",
    "# save out global metadata and measurements\n",
    "with pd.ExcelWriter(os.path.join(save_directory, f'analysis_output.xlsx')) as writer:\n",
    "    \n",
    "    # write metadata\n",
    "    all_ind_df.to_excel(writer, sheet_name='metadata', index=False)\n",
    "\n",
    "    # SLO\n",
    "    if all_slo_df.shape[0] > 0:\n",
    "        all_slo_df.to_excel(writer, sheet_name='SLO_measurements', index=False)\n",
    "    else:\n",
    "        if analyse_slo:\n",
    "            print('WARNING: analyse_slo flag is 1, but there are no SLO measurements loaded!')\n",
    "\n",
    "    # OCT measurements, save out sheets if populated\n",
    "    if all_oct_linescan_df.shape[0] > 0:\n",
    "        all_oct_linescan_df.to_excel(writer, sheet_name='OCT_Linescan_measurements', index=False)\n",
    "\n",
    "    # Radial scan measurements\n",
    "    if all_oct_radial_df.shape[0] > 0:\n",
    "        all_oct_radial_df.to_excel(writer, sheet_name='OCT_Radial_measurements', index=False)\n",
    "\n",
    "    # Ppole ETDRS measurements\n",
    "    if all_oct_ppole_df.shape[0] > 0: \n",
    "        all_oct_ppole_df.to_excel(writer, sheet_name='OCT_Ppole_ETDRS_measurements', index=False)\n",
    "        img_path = os.path.join(MODULE_PATH, os.path.join('figures','etdrs_posterior_pole_grid.png'))\n",
    "        fname = os.path.split(img_path)[1]\n",
    "        shutil.copy(img_path, os.path.join(save_directory, fname))\n",
    "\n",
    "    # Ppole Posterior Pole Grid measurements\n",
    "    if all_oct_sq_ppole_df.shape[0] > 0:\n",
    "        all_oct_sq_ppole_df.to_excel(writer, sheet_name='OCT_Ppole_Square_measurements', index=False)\n",
    "        img_path = os.path.join(MODULE_PATH, os.path.join('figures','square_posterior_pole_grid.png'))\n",
    "        fname = os.path.split(img_path)[1]\n",
    "        shutil.copy(img_path, os.path.join(save_directory, fname))\n",
    "\n",
    "    # Peripapillary measurements\n",
    "    if all_oct_peri_df.shape[0] > 0:\n",
    "        all_oct_peri_df.to_excel(writer, sheet_name='OCT_Peripapillary_measurements', index=False)\n",
    "\n",
    "    # Save out metadata key and descriptions\n",
    "    utils.metakey_df.to_excel(writer, sheet_name='metadata_keys', index=False)\n",
    "\n",
    "# save out log\n",
    "with open(os.path.join(save_directory, f\"analysis_log.txt\"), \"w\") as f:\n",
    "    for line in all_logging_list:\n",
    "        f.write(line+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c56eec-4e5e-465f-8626-1d1c51785c22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
