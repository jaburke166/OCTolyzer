{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f02e782-8e68-46dc-9a82-68fe61a02a15",
   "metadata": {},
   "source": [
    "# Debugging Jupyter Notebook for OCTolyzer's analysis of H-line/V-line single OCT B-scans\n",
    "\n",
    "This notebook copies the step-by-step process of OCTolyzer's analysis pipeline for single H-line/V-line OCT B-scan analysis, and should provide the end-user with the means of debugging the pipeline by testing each step individually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c07f855-5d7c-4bc5-8f69-8516689d5046",
   "metadata": {},
   "source": [
    "### Add OCTolyzer to system paths to permit access to analysis files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6fad52-9078-4b99-8f57-6d9a1f4a17df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from importlib import reload\n",
    "sys.path.append(r'../')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83c575a-a8fd-48bc-a2f2-8535df4b504f",
   "metadata": {},
   "source": [
    "### Import necessary packages and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299dae08-b081-4fcb-81d2-df70c51fcd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from octolyzer import utils, analyse, analyse_slo, main\n",
    "from octolyzer.segment.octseg import choroidalyzer_inference, deepgpet_inference\n",
    "from octolyzer.segment.sloseg import slo_inference, avo_inference, fov_inference\n",
    "from octolyzer.measure.bscan.thickness_maps import grid, map as map_module\n",
    "from octolyzer.measure.bscan import bscan_measurements, utils as chor_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c3c486-1ed6-47c0-a257-af18292ca591",
   "metadata": {},
   "source": [
    "### Define the file you want to use to debug, the `path` is the only variable to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7122613d-17f7-4c3c-aa84-768c793cbe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY_LAYER_DICT = {\"ILM\": \"Inner Limiting Membrane\",\n",
    "                  \"RNFL\": \"Retinal Nerve Fiber Layer\",\n",
    "                  \"GCL\": \"Ganglion Cell Layer\",\n",
    "                  \"IPL\": \"Inner Plexiform Layer\",\n",
    "                  \"INL\": \"Inner Nuclear Layer\",\n",
    "                  \"OPL\": \"Outer Plexiform Layer\",\n",
    "                  \"ELM\": \"External Limiting Membrane\", # Outer nuclear layer\n",
    "                  \"PR1\": \"Photoreceptor Layer 1\",\n",
    "                  \"PR2\": \"Photoreceptor Layer 2\",\n",
    "                  \"RPE\": \"Retinal Pigment Epithelium\",\n",
    "                  \"BM\": \"Bruch's Membrane Complex\", \n",
    "                  \"CHORupper\": \"Bruch's Membrane - Choroid boundary\",\n",
    "                  \"CHORlower\":\"Choroid - Sclera boundary\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1df9817-efbb-4391-8d6c-ed8a69028321",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"../demo/input/Ppole_1.vol\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72d9e9b-cb3d-43b2-829e-def008215b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = os.path.split(path)[1].split(\".\")[0]\n",
    "\n",
    "save_path = f\"check_ppole/{fname}\"\n",
    "segmentation_directory = f\"check_ppole/oct_segmentations\"\n",
    "\n",
    "if not os.path.exists(os.path.split(save_path)[0]):\n",
    "    os.mkdir(os.path.split(save_path)[0])\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    os.mkdir(save_path)\n",
    "\n",
    "if not os.path.exists(segmentation_directory):\n",
    "    os.mkdir(segmentation_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc7d5af-8a32-4b70-95f7-4b8a1aabaccf",
   "metadata": {},
   "source": [
    "## Set the relevant configuration parameters in `param_dict` to whatever is relevant to your analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80881b42-28b9-4fc4-9254-eff1d55b4fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {\n",
    "    \"save_individual_segmentations\": 1,\n",
    "    \"save_individual_images\": 1,\n",
    "    \"preprocess_bscans\": 1,\n",
    "    \"analyse_choroid\": 1,\n",
    "    \"analyse_slo\": 1,\n",
    "    \"custom_maps\": ['ILM_OPL'], # this cannot be \"0\" like it is in config.txt - it is an empty list\n",
    "    \"analyse_all_maps\": 1,\n",
    "    \"analyse_square_grid\": 1,\n",
    "    \"choroid_measure_type\": \"perpendicular\",\n",
    "    \"linescan_roi_distance\": 3000\n",
    "}\n",
    "\n",
    "# flags for choroid analysis, preprocessing bscans\n",
    "preprocess_data = param_dict[\"preprocess_bscans\"]\n",
    "\n",
    "# For saving out representative Bscan/SLO/segmentation masks\n",
    "save_ind_segmentations = param_dict[\"save_individual_segmentations\"]\n",
    "save_ind_images = param_dict[\"save_individual_images\"]\n",
    "\n",
    "# Custom retinal thickness maps\n",
    "custom_maps = param_dict[\"custom_maps\"]\n",
    "all_maps = param_dict[\"analyse_all_maps\"]\n",
    "\n",
    "# analysing choroid?\n",
    "analyse_choroid = param_dict['analyse_choroid']\n",
    "\n",
    "# square grid for Ppole\n",
    "sq_grid_flag = param_dict['analyse_square_grid']\n",
    "\n",
    "# analysing SLO?\n",
    "analyse_slo_flag = param_dict['analyse_slo']\n",
    "\n",
    "# User-specified measure type for choroid\n",
    "chor_measure_type = param_dict['choroid_measure_type']\n",
    "\n",
    "# User-specified ROI distance either side of fovea\n",
    "macula_rum = param_dict['linescan_roi_distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44befe23-f0aa-4499-9400-4c2558ea7f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default we save individual results and collate segmentations\n",
    "collate_segmentations = 1\n",
    "have_slo = 1 # Assume we have the SLO as these are .vol files\n",
    "\n",
    "# Default bscan/slo measurement parameters\n",
    "N_measures = \"all\" # Measuring all thicknesses across ROI to average over\n",
    "N_avgs = 0 # Robust thickness estimation, only relevant when N_measures is an integer\n",
    "chor_linescan_measure_type = chor_measure_type # Measuring type for choroidal metrics across OCT Linescans\n",
    "chor_ppole_measure_type = chor_measure_type # Measuring type for choroidal metrics across OCT Volumes\n",
    "ret_measure_type = 'vertical' # Measuring retina column-wise (via A-scans) according to most devices/literature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707d1164-bd78-44a6-b3d0-e5a6f2eebf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default parameters for thickness maps: ETDRS grid and optional square grid\n",
    "etdrs_kwds = {\"etdrs_microns\":[1000,3000,6000]}\n",
    "square_kwds = {\"N_grid\":8, \"grid_size\":7000}\n",
    "map_flags = [1, sq_grid_flag]\n",
    "map_kwds = [etdrs_kwds, square_kwds]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32e9cec-a6d3-4b72-97f5-b4f60f83062d",
   "metadata": {},
   "source": [
    "### Load in data from `.vol` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3566fb5b-a36f-454e-b5d5-fdbb411ff275",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=1\n",
    "oct_output = []\n",
    "logging_list=[]\n",
    "output = utils.load_volfile(path, preprocess=preprocess_data*analyse_choroid, verbose=verbose,\n",
    "                            custom_maps=custom_maps, logging=logging_list)\n",
    "bscan_data, metadata, slo_output, layer_pairwise, logging_list = output\n",
    "(slo, slo_acq_fixed, slo_acq, (slo_pad_x, slo_pad_y)) = slo_output\n",
    "slo_pad_xy = np.array([slo_pad_x[0], slo_pad_y[0]])\n",
    "N_scans, M, N = bscan_data.shape\n",
    "slo_N = slo.shape[0]\n",
    "oct_output.append(bscan_data)\n",
    "\n",
    "# Pixel spacing, SLO pixel scaling is assumed as isotropic\n",
    "scaleX, scaleY, scaleZ = metadata[\"bscan_scale_x\"],metadata[\"bscan_scale_y\"],metadata[\"bscan_scale_z\"]\n",
    "bscan_scale = (scaleX, scaleY)\n",
    "bscan_ROI = metadata[\"bscan_ROI_mm\"]\n",
    "slo_scale = metadata[\"slo_scale_xy\"]\n",
    "\n",
    "# Analyse the SLO image\n",
    "scan_type = metadata[\"bscan_type\"]\n",
    "scan_location = metadata[\"location\"]\n",
    "if scan_location == \"peripapillary\":\n",
    "    slo_location = \"Optic disc\"\n",
    "else:\n",
    "    slo_location = \"Macula\"\n",
    "eye = metadata[\"eye\"]\n",
    "\n",
    "output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266c8963-8502-46fb-9566-7fdeb5c17379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect retinal layer keys\n",
    "pairwise_keys = list(layer_pairwise.keys())\n",
    "layer_keys = list(set(pd.DataFrame(pairwise_keys).reset_index(drop=True)[0].str.split(\"_\", expand=True).values.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31947d0d-d935-4790-ac9e-5bf169d26d1a",
   "metadata": {},
   "source": [
    "### Load in SLO models and analyse SLO (assuming the SLO analysis is *not* where the error is coming from)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e10a30-9263-4fe7-9c9c-575a6e371d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "slo_metrics = False\n",
    "segmentation_dict = {}\n",
    "slo_model = slo_inference.SLOSegmenter()\n",
    "fov_model = fov_inference.FOVSegmenter()\n",
    "avo_model = avo_inference.AVOSegmenter()\n",
    "slo_analysis_output = analyse_slo.analyse(255*slo, save_path,\n",
    "                                        slo_scale, slo_location, eye,\n",
    "                                        slo_model, avo_model, fov_model,\n",
    "                                        save_images=save_ind_segmentations, \n",
    "                                        compute_metrics=slo_metrics, verbose=verbose, \n",
    "                                        collate_segmentations=True, segmentation_dict=segmentation_dict)\n",
    "slo_meta_df, slo_measure_dfs, _, slo_segmentations, slo_logging_list = slo_analysis_output\n",
    "slo_missing_fovea = slo_meta_df.slo_missing_fovea.values[0].astype(bool)\n",
    "logging_list.extend(slo_logging_list)\n",
    "slo_avimout = slo_segmentations[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eadd4e8-a0cd-4b5d-9348-43e9c65e2919",
   "metadata": {},
   "source": [
    "### Load in choroid segmentation models and segment (if `analyse_choroid` is 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f361c1-24f1-4abb-b332-e6c51199e515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alert to user we are analysing OCT from here on\n",
    "msg = f\"\\n\\nANALYSING OCT of {fname}.\\n\"\n",
    "logging_list.append(msg)\n",
    "if verbose:\n",
    "    print(msg)\n",
    "\n",
    "choroidalyzer = choroidalyzer_inference.Choroidalyzer()\n",
    "deepgpet = deepgpet_inference.DeepGPET()\n",
    "\n",
    "if analyse_choroid:\n",
    "    msg = \"Segmenting choroid and fovea...\"\n",
    "else:\n",
    "    msg = \"Detecting fovea for grid/ROI alignment (through use of Choroidalyzer)...\"\n",
    "logging_list.append(msg)\n",
    "if verbose:\n",
    "    print(msg)\n",
    "    \n",
    "# If macula-centred, use Choroidalyzer. If optic disc-centred, use deepGPET  \n",
    "if scan_location == \"macular\":\n",
    "    if N_scans == 1 or choroidalyzer.device == 'cpu':\n",
    "        rvfmasks, foveas, fov_scores = choroidalyzer.predict_list(bscan_data, soft_pred=True)\n",
    "    else:\n",
    "        rvfmasks, foveas, fov_scores = choroidalyzer.predict_batch(bscan_data, soft_pred=True)\n",
    "elif scan_location == \"peripapillary\":\n",
    "    rvfmasks = deepgpet.predict_list(bscan_data, soft_pred=True)\n",
    "\n",
    "# Resolve fovea detection. If at origin then threshold too high, apply filter function and warn user.\n",
    "if scan_location != \"peripapillary\":\n",
    "    # Method 1: default to middle of stack, unreliable due to poor acquisition but mostly correct\n",
    "    # fovea_slice_num = N_scans//2 \n",
    "    \n",
    "    # Method 2: detect fovea based on the highest score from Choroidalyzer, unreliable due to poor segmentation but mostly correct.\n",
    "    if scan_type == 'Ppole':\n",
    "        fovea_slice_num = int(fov_scores.argmax(axis=0)[0])\n",
    "    else:\n",
    "        fovea_slice_num = N_scans//2 \n",
    "    \n",
    "    # Extract fovea from list using fovea_slice_num\n",
    "    fovea = foveas[fovea_slice_num]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfd9446-6506-4790-b133-f0c8814685eb",
   "metadata": {},
   "source": [
    "### Organise segmentations for map generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbadc585-5b53-4ea5-872b-86054b251995",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = f\"\"\"\\nGenerating thickness and volume maps following ETDRS (0.5mm,1.5mm,3mm radial concentric grids).\n",
    "All retinal measurements are made vertically, i.e. with respect to the image axis (vertical).\n",
    "All choroidal measurements are made {chor_measure_type}.\n",
    "NOTE: Subregion volumes will not be computed for CVI map.\"\"\"\n",
    "logging_list.append(msg)\n",
    "if verbose:\n",
    "    print(msg)\n",
    "\n",
    "# Extract parameters for generating maps, rmove any vessel pixels outside choroid region for vmasks\n",
    "if analyse_choroid:\n",
    "    \n",
    "    # Error handling for unexpected issues in volume stack when post-processing choroid segmentations\n",
    "    rmasks = []\n",
    "    rtraces = []\n",
    "    vmasks = []\n",
    "    for i, rvf_i in enumerate(rvfmasks):\n",
    "        try:\n",
    "            trace = utils.get_trace(rvf_i[0], 0.5, align=False)\n",
    "            rtraces.append(trace)\n",
    "            rmasks.append(utils.rebuild_mask(trace, img_shape=(M,N)))\n",
    "        except:\n",
    "            rtraces.append((-1*np.ones((N,2)), -1*np.ones((N,2))))\n",
    "            rmasks.append(np.zeros((M, N)))\n",
    "    rmasks = np.array(rmasks)\n",
    "    vmasks = np.array([rmask*rvf_i[1] for (rmask, rvf_i) in zip(rmasks, rvfmasks)])\n",
    "\n",
    "# By default setup default choroid and retinal maps.\n",
    "if analyse_choroid:\n",
    "    ppole_keys = [\"choroid\", \"choroid_vessel\", 'ILM_BM']\n",
    "    ppole_units = ['[um]', '[um2]', '[um]']\n",
    "    ppole_segs = [rmasks, rmasks, layer_pairwise['ILM_BM']]\n",
    "else:\n",
    "    ppole_keys = ['ILM_BM']\n",
    "    ppole_units = ['[um]']\n",
    "    ppole_segs = [layer_pairwise['ILM_BM']]\n",
    "\n",
    "# If retina fully segmentd, then we can also extract other custom_maps.\n",
    "if len(layer_pairwise) > 1:\n",
    "    if all_maps:\n",
    "        for key_pair in pairwise_keys:\n",
    "            if key_pair not in custom_maps:\n",
    "                ppole_keys.append(key_pair)\n",
    "                ppole_units.append('[um]')\n",
    "                ppole_segs.append(layer_pairwise[key_pair])\n",
    "    if len(custom_maps) > 0:\n",
    "        for key_pair in custom_maps:\n",
    "            if key_pair not in ppole_keys:\n",
    "                ppole_keys.append(key_pair)\n",
    "                ppole_units.append('[um]')\n",
    "                ppole_segs.append(layer_pairwise[key_pair])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad91eb06-7e9c-469a-95ae-df4b0cba9cb2",
   "metadata": {},
   "source": [
    "### Rename layer and maps and initialise measurement dictionaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ee6ce9-6bde-4b70-b914-af418ac4fd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename summary layers\n",
    "keys_to_names = ['ILM_BM', 'ILM_ELM', 'ELM_BM']\n",
    "names_to_keys = ['retina', 'inner_retina', 'outer_retina']\n",
    "ppole_keys = np.array(ppole_keys).astype('<U14')\n",
    "for k2n, n2k in zip(keys_to_names, names_to_keys):\n",
    "    ppole_keys[ppole_keys==k2n] = n2k\n",
    "ppole_keys = list(ppole_keys)\n",
    "\n",
    "# Initialise dictionaries to store maps and feature measurements from volume scans\n",
    "grid_type = [\"etdrs\", \"square\"]\n",
    "map_dict = {}\n",
    "measure_dict = {}\n",
    "volmeasure_dict = {}\n",
    "if collate_segmentations:\n",
    "    ctmap_args = {}\n",
    "    ctmap_args['core'] = [slo, fname, segmentation_directory]\n",
    "for (m_flag, m_type) in zip(map_flags, grid_type):\n",
    "    if m_flag:\n",
    "        measure_dict[m_type] = {}\n",
    "        volmeasure_dict[m_type] = {}\n",
    "\n",
    "# save out thickness maps and visualisations in single folder to clean up directory\n",
    "map_save_path = os.path.join(save_path,'thickness_maps')\n",
    "if not os.path.exists(map_save_path):\n",
    "    os.mkdir(map_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e437c047-e020-4222-b59e-4919fd46f69c",
   "metadata": {},
   "source": [
    "### Compute maps and measure ETDRS/Square etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f45e16-dd27-4815-9d5d-4d0579a0e00a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loop over segmented layers and generate user-specified maps\n",
    "for key, seg in zip(ppole_keys, ppole_segs):\n",
    "\n",
    "    # Log to user and take special care for choroid_vessel map\n",
    "    msg = f\"    {key} thickness map\"\n",
    "    ves_chorsegs = None\n",
    "    measure_type = \"vertical\"\n",
    "    if \"choroid\" in key:\n",
    "        measure_type = ret_measure_type\n",
    "        if key == \"choroid_vessel\":\n",
    "            ves_chorsegs = vmasks\n",
    "            measure_type = chor_ppole_measure_type\n",
    "            msg = f\"    choroid vessel and vascular index maps\"                    \n",
    "\n",
    "    # Compute map\n",
    "    logging_list.append(msg)\n",
    "    if verbose:\n",
    "        print(msg)\n",
    "    map_output = map_module.construct_map(slo, \n",
    "                                          slo_acq,\n",
    "                                          slo_pad_xy,\n",
    "                                          seg,\n",
    "                                          fovea, \n",
    "                                          fovea_slice_num, \n",
    "                                          bscan_scale, \n",
    "                                          scaleZ,\n",
    "                                          slo_N=slo_N, \n",
    "                                          oct_N=N,\n",
    "                                          log_list=[],\n",
    "                                          ves_chorsegs=ves_chorsegs,\n",
    "                                          measure_type=measure_type)\n",
    "\n",
    "    # Measure grids on the maps and save out in dedicated folder \n",
    "    for i,(m_flag, m_kwd) in enumerate(zip(map_flags, map_kwds)):\n",
    "\n",
    "        # If flagged to measure ETDRS/Posterior pole grid then allow grid measurement\n",
    "        m_type = grid_type[i]\n",
    "        if m_flag:\n",
    "\n",
    "            # For 'choroid_vessel', first measure CVI map with floats as CVI in [0,1]\n",
    "            if key == \"choroid_vessel\":\n",
    "                slo_output, macular_map, (angle, fovea_at_slo, acq_centre), cvi_map, map_messages = map_output\n",
    "                logging_list.extend(map_messages)\n",
    "                cvi_key = \"choroid_CVI\"\n",
    "                ppole_units.append('')\n",
    "                ppole_keys.append(cvi_key)\n",
    "                fname_key = fname+f\"_{cvi_key}_{m_type}_map\"\n",
    "\n",
    "                # CVI-specific grid measurement\n",
    "                dtype = np.float64\n",
    "                grid_measure_output = grid.measure_grid(cvi_map, \n",
    "                                                        fovea_at_slo, \n",
    "                                                        scaleX, \n",
    "                                                        eye, \n",
    "                                                        rotate=angle, \n",
    "                                                        measure_type=m_type, \n",
    "                                                        grid_kwds=m_kwd,\n",
    "                                                        interp=True, \n",
    "                                                        plot=save_ind_segmentations, \n",
    "                                                        slo=slo_output, \n",
    "                                                        dtype=dtype,\n",
    "                                                        fname=fname_key, \n",
    "                                                        save_path=map_save_path)\n",
    "                grid_output, gridvol_output, grid_messages = grid_measure_output\n",
    "\n",
    "                # Append results to dictionaries\n",
    "                logging_list.extend(grid_messages)                                \n",
    "                measure_dict[m_type][cvi_key] = grid_output\n",
    "                volmeasure_dict[m_type][cvi_key] = gridvol_output\n",
    "                map_dict[cvi_key] = pd.DataFrame(cvi_map)\n",
    "\n",
    "                # Necessary for visualisation\n",
    "                if m_type=='etdrs' and collate_segmentations:\n",
    "                    ctmap_args[cvi_key] = [cvi_map, \n",
    "                                           fovea_at_slo, \n",
    "                                           scaleX, \n",
    "                                           eye, \n",
    "                                           angle, \n",
    "                                           dtype,\n",
    "                                           grid_output, \n",
    "                                           gridvol_output]\n",
    "            \n",
    "            else:\n",
    "\n",
    "                # Standard output from constructing macular map when key != 'choroid_vessel'\n",
    "                slo_output, macular_map, (angle, fovea_at_slo, acq_centre), map_messages = map_output\n",
    "                logging_list.extend(map_messages)\n",
    "\n",
    "            # Measure grid for all other metrics and layers other than CVI\n",
    "            dtype = np.uint64\n",
    "            unit = 'thickness' if m_type != 'choroid_vessel' else 'area'\n",
    "            grid_measure_output = grid.measure_grid(macular_map, \n",
    "                                                    fovea_at_slo, \n",
    "                                                    scaleX, \n",
    "                                                    eye, \n",
    "                                                    rotate=angle, \n",
    "                                                    measure_type=m_type, \n",
    "                                                    grid_kwds=m_kwd,\n",
    "                                                    interp=True, \n",
    "                                                    plot=save_ind_segmentations, \n",
    "                                                    slo=slo_output, \n",
    "                                                    dtype=dtype,\n",
    "                                                    fname=fname+f\"_{key}_{m_type}_{unit}_map\", \n",
    "                                                    save_path=map_save_path)\n",
    "            grid_output, gridvol_output, grid_messages = grid_measure_output\n",
    "\n",
    "            # Append results to dictionaries\n",
    "            logging_list.extend(grid_messages)                                                                 \n",
    "            measure_dict[m_type][key] = grid_output\n",
    "            volmeasure_dict[m_type][key] = gridvol_output\n",
    "\n",
    "        # Append results to dictionaries\n",
    "        map_dict[key] = pd.DataFrame(macular_map)\n",
    "        if m_type=='etdrs' and key in ['retina','choroid'] and collate_segmentations:\n",
    "            ctmap_args[key] = [macular_map, \n",
    "                               fovea_at_slo, \n",
    "                               scaleX, \n",
    "                               eye, \n",
    "                               angle, \n",
    "                               dtype,\n",
    "                               grid_output, \n",
    "                               gridvol_output]\n",
    "\n",
    "# Log to user that maps are being saved out\n",
    "msg = f'Saving out key macular maps.'\n",
    "logging_list.append(msg)\n",
    "if verbose:\n",
    "    print(msg)\n",
    "\n",
    "# Plot core maps (retina, choroid, CVI) into single figure and save out\n",
    "if collate_segmentations and map_flags[0]==1:\n",
    "    fig = grid.plot_multiple_grids(ctmap_args)\n",
    "    fig.savefig(os.path.join(save_path, fname+'.png'), bbox_inches=\"tight\", transparent=False)\n",
    "plt.close()\n",
    "\n",
    "# Save out macular maps as .npy files \n",
    "for key, macular_map in map_dict.items():\n",
    "    unit = ''\n",
    "    if key != 'choroid_CVI':\n",
    "        unit = 'thickness' if m_type != 'choroid_vessel' else 'area'\n",
    "    np.save(os.path.join(map_save_path, f\"{fname}_{key}_{unit}_map.npy\"), macular_map)\n",
    "\n",
    "# Add choroid Ppole traces to retinal segmentations\n",
    "if analyse_choroid:\n",
    "    layer_pairwise[\"CHORupper_CHORlower\"] = rtraces\n",
    "    layer_keys.append(\"CHORupper\")\n",
    "    layer_keys.append(\"CHORlower\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf08ae2-9578-4dc0-bd0d-a72fc817aeaa",
   "metadata": {},
   "source": [
    "### Save out B-scans with segmentations overlaid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31064d06-6742-46e1-851f-fb25a04de99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save out volumetric OCT B-scan segmentations\n",
    "if save_ind_segmentations:\n",
    "\n",
    "    msg = f'Saving out key visualisations of segmentations overlaid onto posterior pole B-scans.'\n",
    "    logging_list.append(msg)\n",
    "    if verbose:\n",
    "        print(msg)\n",
    "\n",
    "    # Save out fovea-centred B-scan segmentation visualisation\n",
    "    if analyse_choroid:\n",
    "        fovea_vmask = vmasks[fovea_slice_num]\n",
    "        fovea_vcmap = np.concatenate([fovea_vmask[...,np.newaxis]] \n",
    "                + 2*[np.zeros_like(fovea_vmask)[...,np.newaxis]] \n",
    "                + [fovea_vmask[...,np.newaxis] > 0.01], axis=-1)\n",
    "    else:\n",
    "        vmasks = None# Plot segmentations over fovea-centred B-scan\n",
    "\n",
    "    layer_keys_copied = layer_keys.copy()\n",
    "    fig, (ax0,ax) = plt.subplots(1,2,figsize=(12,6))\n",
    "    ax0.imshow(bscan_data[fovea_slice_num], cmap='gray')\n",
    "    ax.imshow(bscan_data[fovea_slice_num], cmap=\"gray\")\n",
    "    for key, tr in layer_pairwise.items():\n",
    "        for (k, t) in zip(key.split(\"_\"), tr[fovea_slice_num]):\n",
    "            if k in layer_keys_copied:\n",
    "                ax.plot(t[:,0],t[:,1], label='_ignore', zorder=2)\n",
    "                layer_keys_copied.remove(k)\n",
    "    ax.scatter(fovea[0], fovea[1], s=200, marker=\"X\", edgecolor=(0,0,0), \n",
    "                color=\"r\", linewidth=1, zorder=3, label='Detected fovea position')\n",
    "    if analyse_choroid:\n",
    "        ax.imshow(fovea_vcmap, alpha=0.5, zorder=2)\n",
    "    ax.axis([0, N-1, M-1, 0])\n",
    "    ax.legend(fontsize=16)\n",
    "    ax.set_axis_off()\n",
    "    ax0.set_axis_off()\n",
    "    fig.tight_layout(pad = 0)\n",
    "    fig.savefig(os.path.join(save_path, f\"{fname}_fovea_octseg.png\"), bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    \n",
    "    # Stitch all B-scans to create \"contact sheet\" for checking\n",
    "    # Organise stacking of B-scans into rows & columns\n",
    "    if N_scans in [61,31,45,7]:\n",
    "        if N_scans == 61:\n",
    "            reshape_idx = (10,6)\n",
    "        elif N_scans == 31:\n",
    "            reshape_idx = (5,6)\n",
    "        elif N_scans == 45:\n",
    "            reshape_idx = (11,4)\n",
    "        elif N_scans == 7:\n",
    "            reshape_idx = (2,3)\n",
    "        utils.plot_composite_bscans(bscan_data, \n",
    "                                    vmasks, \n",
    "                                    fovea_slice_num, \n",
    "                                    layer_pairwise, \n",
    "                                    reshape_idx, \n",
    "                                    analyse_choroid, \n",
    "                                    fname, \n",
    "                                    save_path)\n",
    "    else:\n",
    "        msg = f'Volume scan with {N_scans} B-scans cannot currently be reshaped into single composite image.\\nThis is likely because the development team has not had access to this kind of volume scans before. Please raise an issue on the GitHub repository.'\n",
    "        logging_list.append(msg)\n",
    "        if verbose:\n",
    "            print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70933596-b811-40a0-a177-f0f8a13e5fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ppole measurement metadata\n",
    "metadata[\"bscan_fovea_x\"] = fovea[0]\n",
    "metadata[\"bscan_fovea_y\"] = fovea[1]\n",
    "metadata[\"slo_fovea_x\"] = fovea_at_slo[0]\n",
    "metadata[\"slo_fovea_y\"] = fovea_at_slo[1]\n",
    "metadata[\"slo_missing_fovea\"] = slo_missing_fovea\n",
    "metadata[\"acquisition_angle_degrees\"] = angle\n",
    "metadata[\"choroid_measure_type\"] = chor_measure_type\n",
    "\n",
    "# Add metric units to the end of metadata\n",
    "metadata[\"thickness_units\"] = \"microns\"\n",
    "metadata[\"choroid_vascular_index_units\"] = 'dimensionless'\n",
    "metadata[\"choroid_vessel_density_units\"] = \"micron2\"\n",
    "metadata[\"area_units\"] = \"mm2\"\n",
    "metadata[\"volume_units\"] = \"mm3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee8698c-b6ec-47da-b9bb-6c4ae295ae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If saving out bscan and slo image. If ppole, only saying out bscan at fovea\n",
    "# This is automatically done for AV-line scans.\n",
    "if save_ind_images:\n",
    "    if have_slo:\n",
    "        cv2.imwrite(os.path.join(save_path,f\"{fname}_slo.png\"), \n",
    "                    (255*slo).astype(np.uint8))\n",
    "    if scan_location != 'peripapillary':\n",
    "        cv2.imwrite(os.path.join(save_path,f\"{fname}_slo_acquisition_lines.png\"), \n",
    "                    (255*slo_acq).astype(np.uint8))\n",
    "        cv2.imwrite(os.path.join(save_path,f\"{fname}_bscan_fovea.png\"), \n",
    "                (255*bscan_data[fovea_slice_num]).astype(np.uint8))\n",
    "    else:\n",
    "        cv2.imwrite(os.path.join(save_path,f\"{fname}_bscan.png\"), \n",
    "                (255*bscan_data[0]).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1876e55d-a2e4-488e-84dd-ca4fd8ea6123",
   "metadata": {},
   "source": [
    "### Organise segmentations to be saved out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9945f90-42b5-42b9-ac2d-d96619b3b560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer keys, ordered anaomtically\n",
    "ordered_keys = np.array(list(KEY_LAYER_DICT))\n",
    "key_df = pd.DataFrame({\"key\":layer_keys,\"layer\":[KEY_LAYER_DICT[key] for key in layer_keys],\n",
    "                    \"layer_number\":[np.where(key == ordered_keys)[0][0] for key in layer_keys]})\n",
    "key_df = key_df.sort_values(\"layer_number\")\n",
    "del key_df[\"layer_number\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc56a640-fb09-420d-8492-a7443054649c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organise layer segmentations to be saved out - overcomplicated as I am working\n",
    "# with pairwise segmentation traces, not individual ones. \n",
    "seg_df = {}\n",
    "layer_keys_copied = layer_keys.copy()\n",
    "for key, trace_xy_all in layer_pairwise.items():\n",
    "    for k_idx, k in enumerate(key.split(\"_\")):\n",
    "        if k in layer_keys_copied:\n",
    "            all_ytr = {}\n",
    "            for s_idx, trace in enumerate(trace_xy_all):\n",
    "                t = trace[k_idx]\n",
    "                (xtr, ytr) = t[:,0], t[:,1]\n",
    "                try:\n",
    "                    xst, xen = xtr[[0,-1]]\n",
    "                    ytr_pad = np.pad(ytr, ((max(xst-1,0), N-xen)), mode=\"constant\")\n",
    "                    all_ytr[s_idx] = {i:ytr_pad[i] for i in range(N)}\n",
    "                except Exception as e:\n",
    "                    message = f\"\\nAn exception of type {type(e).__name__} occurred. Error description:\\n{e.args[0]}\"\n",
    "                    user_fail = f\"Failed to store segmentations for B-scan {s_idx+1}/{N_scans} for layer {k}. Saving as NAs\"\n",
    "                    log_save = [message, user_fail]\n",
    "                    logging_list.extend(log_save)\n",
    "                    if verbose:\n",
    "                        print(message)\n",
    "                        print(user_fail)\n",
    "                    all_ytr[s_idx] = {i:np.nan for i in range(N)}\n",
    "\n",
    "            layer_keys_copied.remove(k)\n",
    "            df = utils.nested_dict_to_df(all_ytr).reset_index()\n",
    "            df = df.rename({\"index\":\"scan_number\"}, inplace=False, axis=1)\n",
    "            seg_df[k] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8255f27c-c053-4720-81ff-b217f692db1e",
   "metadata": {},
   "source": [
    "### Organise measurements into DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d61880-fa5c-4097-8402-e53acc1fee3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organise feature measurements for Ppole volume scans\n",
    "ppole_key_unit_df = pd.DataFrame({'map_name':ppole_keys, 'units':ppole_units}).drop_duplicates()\n",
    "ppole_vol_unit_df = ppole_key_unit_df.copy()\n",
    "ppole_vol_unit_df['units'] = '[mm3]'\n",
    "\n",
    "# Extract only retinal layers\n",
    "retina_layers = np.array(list(KEY_LAYER_DICT.keys())[:-2])\n",
    "pairwise_keys = [f\"{k1}_{k2}\" for (k1,k2) in zip(retina_layers[:-1], retina_layers[1:])]\n",
    "all_maps = ppole_key_unit_df.map_name.values\n",
    "\n",
    "# Order rows of results dataframes anatomically\n",
    "if analyse_choroid:\n",
    "    choroid_maps = ['choroid', 'choroid_CVI', 'choroid_vessel']\n",
    "else:\n",
    "    choroid_maps = []\n",
    "retina_sum_maps = []\n",
    "retina_custom_maps = []\n",
    "retina_layer_maps = []\n",
    "for map_name in all_maps:\n",
    "    if 'retina' in map_name:\n",
    "        retina_sum_maps.append(map_name)\n",
    "    elif 'choroid' not in map_name:\n",
    "        if map_name in pairwise_keys:\n",
    "            retina_layer_maps.append(map_name)\n",
    "        else:\n",
    "            retina_custom_maps.append(map_name)\n",
    "ordered_maps = retina_sum_maps+retina_layer_maps+retina_custom_maps+choroid_maps\n",
    "\n",
    "# Collect grid thickness/volume measurements in DataFrames\n",
    "measure_dfs = []\n",
    "measure_grids = []\n",
    "volmeasure_dfs = []\n",
    "for grid_type in [\"etdrs\", \"square\"]:\n",
    "    if grid_type in measure_dict.keys():\n",
    "        measure_grids.append(grid_type)\n",
    "\n",
    "        # Unpack dict of dicts\n",
    "        df = measure_dict[grid_type]\n",
    "        df = utils.nested_dict_to_df(df).reset_index()\n",
    "        df = df.rename({\"index\":\"map_name\"}, inplace=False, axis=1)\n",
    "        df = df.merge(ppole_key_unit_df, on='map_name', how='inner')\n",
    "        # add unit column and shift\n",
    "        cols = list(df.columns)\n",
    "        cols.insert(1, cols.pop(cols.index('units')))\n",
    "        df = df.loc[:, cols]\n",
    "        # Order rows anatomically\n",
    "        df['map_name'] = pd.CategoricalIndex(df['map_name'], ordered=True, categories=ordered_maps)\n",
    "        df = df.sort_values('map_name').reset_index(drop=True)\n",
    "        measure_dfs.append(df.drop_duplicates())\n",
    "\n",
    "        # Same for volume dataframes\n",
    "        voldf = volmeasure_dict[grid_type]\n",
    "        voldf = utils.nested_dict_to_df(voldf).reset_index()\n",
    "        voldf = voldf.rename({\"index\":\"map_name\"}, inplace=False, axis=1)\n",
    "        voldf = voldf.merge(ppole_vol_unit_df, on='map_name', how='inner')\n",
    "        cols = list(voldf.columns)\n",
    "        cols.insert(1, cols.pop(cols.index('units')))\n",
    "        voldf = voldf.loc[:, cols]\n",
    "        voldf['map_name'] = pd.CategoricalIndex(voldf['map_name'], ordered=True, categories=ordered_maps)\n",
    "        voldf = voldf.sort_values('map_name').reset_index(drop=True)\n",
    "        volmeasure_dfs.append(voldf.drop_duplicates())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839371f7-2b37-4905-b75f-ccb7add70c1d",
   "metadata": {},
   "source": [
    "### Save out results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a460ae80-0033-4507-858f-0c2f96c539e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save out core results in an .xlsx file\n",
    "meta_df = pd.DataFrame(metadata, index=[0])\n",
    "with pd.ExcelWriter(os.path.join(save_path, f'{fname}_output.xlsx')) as writer:\n",
    "    \n",
    "    # Write metadata\n",
    "    meta_df.to_excel(writer, sheet_name='metadata', index=False)\n",
    "\n",
    "    # Save out metadata key and descriptions\n",
    "    metakeydf = utils.metakey_df\n",
    "    metakeydf = metakeydf[metakeydf.column.isin(list(meta_df.columns))]\n",
    "    metakeydf.to_excel(writer, sheet_name='metadata_keys', index=False)\n",
    "\n",
    "    # Write OCT results, either map measurements (for PPole only) or H-line/V-line/Radial measurements\n",
    "    if scan_type == \"Ppole\":\n",
    "        for measure_df, volmeasure_df, grid_type in zip(measure_dfs, volmeasure_dfs, measure_grids):\n",
    "            measure_df.to_excel(writer, sheet_name=f'{grid_type}_measurements', index=False)\n",
    "            volmeasure_df.to_excel(writer, sheet_name=f'{grid_type}_volume_measurements', index=False)    \n",
    "    elif scan_type != \"AV-line\":\n",
    "        for measure_df in measure_dfs:\n",
    "            measure_df.to_excel(writer, sheet_name=\"oct_measurements\", index=False)\n",
    "\n",
    "    # Write SLO measurements\n",
    "    if slo_analysis_output is not None and analyse_slo:\n",
    "        for df in slo_measure_dfs:\n",
    "            if len(df) > 0:\n",
    "                z = df.zone.iloc[0]\n",
    "                df.to_excel(writer, sheet_name=f'slo_measurements_{z}', index=False)\n",
    "\n",
    "    # Write out segmentations\n",
    "    for key,df in seg_df.items():\n",
    "        if key != key.lower():\n",
    "            name = f\"segmentations_{key}\"\n",
    "        else:\n",
    "            name = f\"maps_{key}\"\n",
    "        df.to_excel(writer, sheet_name=name, index=False)\n",
    "\n",
    "    # write out layer keys\n",
    "    key_df.to_excel(writer, sheet_name=\"layer_keys\", index=False)\n",
    "\n",
    "msg = f\"\\nSaved out metadata, measurements and segmentations.\"\n",
    "logging_list.append(msg)\n",
    "if verbose:\n",
    "    print(msg)\n",
    "\n",
    "# Organise outputs from analysis script\n",
    "oct_measures = measure_dfs.copy()\n",
    "oct_segmentations_maps = [seg_df]\n",
    "if scan_location != 'peripapillary':\n",
    "    oct_segmentations_maps.append(vmasks)\n",
    "if scan_type == \"Ppole\":\n",
    "    oct_segmentations_maps.append(map_dict)\n",
    "    for df in volmeasure_dfs:\n",
    "        oct_measures.append(df)\n",
    "    if sq_grid_flag:\n",
    "        oct_measures = [oct_measures[0],oct_measures[2],oct_measures[1],oct_measures[3]]\n",
    "oct_analysis_output = [meta_df, slo, bscan_data] + [oct_measures] + oct_segmentations_maps + [logging_list]\n",
    "\n",
    "# final log\n",
    "msg = f\"\\nCompleted analysis of {fname}.\\n\"\n",
    "logging_list.append(msg)\n",
    "if verbose:\n",
    "    print(msg)\n",
    "\n",
    "# Save out log\n",
    "with open(os.path.join(save_path, f\"{fname}_log.txt\"), \"w\") as f:\n",
    "    for line in logging_list:\n",
    "        f.write(line+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b5a008-8d62-44f1-88ba-d45b88438e60",
   "metadata": {},
   "source": [
    "# Run OCTolyzer's pipeline from scratch on this file to check whether it works properly before/after debugging. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2b560e-78b5-4e0b-a5a4-d7f030a6cdf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "analyse.analyse(path, save_path=\"check_ppole\", param_dict=param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8039a1a8-bb2e-4784-a8c4-bc0cbfe68448",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
